# TextClassification 

This experiment is used to assign labels to texts or pairs of texts. 

## Train

This mode is used to train a model to assign labels to text. 

You can find details about the parameters to be included in the config file [here](https://github.com/forrestdavis/NLPScholar/tree/main?tab=readme-ov-file#config-details-for-train)

### Data details
You need to have TSV file with the following columns: 
- `textid`: unique id for each text
- `text`: text
- `pair`: the paired text (required only if you want to pass in two texts)
- `label`: the target label


## Evaluate

This mode is used to get predicted labels from the model for every text in the evaluation data set. 

### Parameters to be included in the config: 

#### Required parameters

- `model` (the models to evaluate)
- `datafpath`: File path and name for data TSV
- `predfpath`: File path for where the predictions will be saved

#### Optional parameters
- `id2label`: a mapping that specifies the mapping that the model uses to map numerical label ids to strings. If this is not provided, labels from the tokenizer of a pretrained model used (if present), or just the nummerical values are used. 
- `giveAllLabels`: If True, columns for each label are added to the prediction file along with the probability. If False, only label with maximum probability is provided. Default is False

### Data details

#### Input
This is the file passed into `datafpath`. 

**Required columns**
- `textid`: unique id for each text
- `text`: text
- `pair`: the paired text (required only if you want to pass in two texts)
- `target`: the target label

**Optional columns (used in analysis later)**
- Columns for different conditions



#### Output
This is the file that will be saved in `predfpath`

- `textid` (the ID of the text)
- `model` (the model the predictions come from)
- `tokenizer` (the tokenizer the model used)
- `target` (the target label)
- `predicted` (the predicted label)
- `prob` (the probability of the predicted label)





## Analysis

This mode can be used to get aggregrate metrics (either overall or by target type)

### Parameters to be included in the config: 

#### Required parameters

- `model` (the models to evaluate)
- `predfpath`: File path for where the predictions from `evaluate` were saved
- `resultsfpath`: File path where output of this mode will be saved
- `save`: The final files that should be saved. This can be `by_word`, `by_tokentype`, and/or `by_cond`. If you want multiple files, they should be comma separated. 

#### Optional parameters
- `datafpath`: File path and name for data TSV with condition information
- `conditions`: Which conditions to take into account when creating the `by_cond` file. 
- `f_val`: the value for the f-score. (Default is 1)


### Data details

#### Input
This is the file generated by `evaluate` and passed into `predfpath`. You can optionally pass in a file into `datafpath` if you want metrics split by condition. THis file should minimally have the following columns: 

- `textid` which matches the textid in the predictions
- Any other condition files


#### Output

**`by_target`**
A TSV file with one row per each unique target label type, with precision, recall and fscore for the token type for each condition and model combination. 

**`by_cond`**
A TSV file with one row for each condition and model combination, with accuracy as well as micro and macro precision, recall and fscores. 


